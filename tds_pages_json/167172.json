{
  "topic_id": 167172,
  "title": "Regarding project1 for file not detecting after sending post request",
  "url": "https://discourse.onlinedegree.iitm.ac.in/t/regarding-project1-for-file-not-detecting-after-sending-post-request/167172",
  "posts": [
    {
      "post_id": 594941,
      "author": "Sakshi6479",
      "created_at": "2025-02-14T12:38:47.883000",
      "content": "sir i am getting an error in this function calling which you have demonstrate yesterday , i am attaching my code also the error with it. Please take a look and provide the solution as the deadline is close please help me as soon as possible.\n\nis there anything to do with dockerfile or anything else please explain it how to do it step by step.\n\n\nimport os\nfrom dotenv import load_dotenv\nimport json\nimport requests\nfrom fastapi import FastAPI, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nimport pandas as pd\nfrom fastapi.responses import StreamingResponse, JSONResponse\nfrom typing import Dict, Any, List\nimport subprocess\nimport datetime\nfrom pathlib import Path\nimport sqlite3\n\napp = FastAPI()\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"GET\", \"POST\"],\n    allow_headers=[\"*\"],\n)\n\n#AIPROXY_TOKEN = os.getenv(\"AIPROXY_TOKEN\")\nload_dotenv()\nAIPROXY_TOKEN = os.getenv(\"AIPROXY_TOKEN\", \"enter your token here\")\n\n\ndef sort_contacts(contacts_file_path: str, output_file_path: str):\n    try:\n        contacts = pd.read_json(contacts_file_path)\n        contacts.sort_values([\"last_name\", \"first_name\"]).to_json(output_file_path, orient=\"records\")\n        return {\"message\": f\"Contacts sorted and saved to {output_file_path}\"}\n    except Exception as e:\n        return {\"error\": f\"Failed to sort contacts: {str(e)}\"}\n\n\na4_tool = {\n    \"type\": \"function\",\n    \"function\": {\n        \"name\": \"sort_contacts\",\n        \"description\": \"This function takes data from a json file and sorts the data first by last name and then by first name, then it stores it inside the speicfied location.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"contacts_file_path\": {\n                    \"type\": \"string\",\n                    \"description\": \"The relative path to the input JSON file containing the contacts.\"\n                },\n                \"output_file_path\": {\n                    \"type\": \"string\",\n                    \"description\": \"The relative path to the output JSON file to store the sorted contacts.\"\n                }\n            },\n            \"required\": [\"contacts_file_path\", \"output_file_path\"],\n            \"additionalProperties\": False\n        },\n        \"strict\": True\n    },\n}\n\n\ntools = [bakecake, a1_tool, a2_tool, a3_tool, a4_tool, a5_tool, a6_tool, a7_tool, a8_tool, a9_tool, a10_tool]\n\n\n\ndef query_gpt(user_input: str, tools: list[dict] = tools) -> dict:\n    response = requests.post(\n        url=\"https://aiproxy.sanand.workers.dev/openai/v1/chat/completions\",\n        headers={\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {AIPROXY_TOKEN}\"\n        },\n        json={\n            \"model\": \"gpt-4o-mini\",\n            \"messages\": [\n                {\n                    \"role\": \"user\",\n                    \"content\": user_input\n                }\n            ],\n            \"tools\": tools,\n            \"tool_choice\": \"auto\"\n        }\n    )\n    return response.json()\n\n@app.get(\"/\")\ndef home():\n    return {\"Hello\": \"World\"}\n\n@app.get(\"/read\")\ndef read_file(path: str):\n    try:\n        with open(path, \"r\") as f:\n            return f.read()\n    except Exception as e:\n        raise HTTPException(status_code=404, detail=\"File does not exist\")\n\n@app.post(\"/run\")\nasync def run(task: str):\n    query = query_gpt(task)\n    print(query)  # Print the full response to inspect it.\n    \n    if 'choices' not in query:\n        raise HTTPException(status_code=500, detail=\"Invalid response format from GPT API\")\n    \n    try:\n        tool_calls = query['choices'][0]['message'].get('tool_calls', [])\n        if tool_calls:\n            func_name = tool_calls[0]['function']['name']\n            args = json.loads(tool_calls[0]['function']['arguments'])\n            \n            # Map function names to their respective functions\n            function_map = {\n                \"cakebake\": cakebake,\n                \"install_uv_and_run_datagen\": install_uv_and_run_datagen,\n                \"format_markdown_file\": format_markdown_file,\n                \"count_wednesdays\": count_wednesdays,\n                \"sort_contacts\": sort_contacts,\n                \"extract_recent_logs\": extract_recent_logs,\n                \"create_markdown_index\": create_markdown_index,\n                \"extract_sender_email\": extract_sender_email,\n                \"extract_credit_card_number\": extract_credit_card_number,\n                \"find_similar_comments\": find_similar_comments,\n                \"calculate_gold_ticket_sales\": calculate_gold_ticket_sales,\n            }\n            \n            if func_name in function_map:\n                output = function_map[func_name](**args)\n            else:\n                raise HTTPException(status_code=500, detail=\"Unknown function called\")\n        else:\n            raise HTTPException(status_code=500, detail=\"No function call found in response\")\n    except KeyError as e:\n        raise HTTPException(status_code=500, detail=f\"KeyError: Missing key in response - {str(e)}\")\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error processing the request: {str(e)}\")\n    \n    return output\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n\n\n\nScreenshot 2025-02-14 171217\n2075×1343 176 KB\n\n\n@Saransh_Saini\n , \n@Jivraj\n , \n@carlton"
    },
    {
      "post_id": 594951,
      "author": "carlton",
      "created_at": "2025-02-14T13:01:08.797000",
      "content": "Hi Sakshi,\n\n\nThe error is quite clear, it cannot find the file /data/contacts.json\n\n\nQuestion: What creates the /data/contacts.json file?"
    },
    {
      "post_id": 594962,
      "author": "Sakshi6479",
      "created_at": "2025-02-14T13:30:26.445000",
      "content": "so how to do it sir that the thing i am not able to understand."
    },
    {
      "post_id": 594971,
      "author": "Sakshi6479",
      "created_at": "2025-02-14T13:59:34.581000",
      "content": "sir kindly help me with this the time is running and i am still at the starting stage of project.\n\n\n@carlton"
    },
    {
      "post_id": 594980,
      "author": "Saransh_Saini",
      "created_at": "2025-02-14T14:16:24.088000",
      "content": "Sakshi as the error says it’s unable to find your file. Try adding a . (dot) before the location."
    },
    {
      "post_id": 595001,
      "author": "Sakshi6479",
      "created_at": "2025-02-14T14:32:12.846000",
      "content": "sir i have used the dot(.) while sending the request to postman in the query which i provided to the task. Is the dot(.) should be added somewhere else?"
    },
    {
      "post_id": 595018,
      "author": "Saransh_Saini",
      "created_at": "2025-02-14T15:07:26.713000",
      "content": "If you have added that dot as a prefix to your locations then, you would have to structure your query_gpt in such a way that it takes these dots into consideration."
    },
    {
      "post_id": 595104,
      "author": "Sakshi6479",
      "created_at": "2025-02-14T17:48:35.347000",
      "content": "sir i have tried that by putting by doing this\n\n\nimport os\nfrom dotenv import load_dotenv\nimport json\nimport requests\nfrom dateutil import parser as date_parser\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom fastapi import FastAPI, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nimport pandas as pd\nfrom fastapi.responses import StreamingResponse, JSONResponse\nfrom typing import Dict, Any, List\nimport subprocess\nimport datetime\nfrom pathlib import Path\nimport sqlite3\nimport base64\nimport mimetypes\nimport numpy as np\n\n\napp = FastAPI()\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"GET\", \"POST\"],\n    allow_headers=[\"*\"],\n)\n\n#AIPROXY_TOKEN = os.getenv(\"AIPROXY_TOKEN\")\nAIPROXY_TOKEN = os.getenv(\"AIPROXY_TOKEN\")\ndef cakebake(no_people: int, flavor: str):\n    return {\"message\": f\"Making a {flavor} cake for {no_people} people\"}\n\nbakecake = {\n    \"type\": \"function\",\n    \"function\": {\n        \"name\": \"cakebake\",\n        \"description\": \"Make a cake for all iitm students contain its emailids\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"no_people\": {\n                    \"type\": \"integer\",\n                    \"description\": \"Number of people\"\n                },\n                \"flavor\": {\n                    \"type\": \"string\",\n                    \"description\": \"Flavor of the cake\"\n                }\n            },\n            \"required\": [\"no_people\", \"flavor\"],\n            \"additionalProperties\": False\n        },\n        \"strict\": True\n    }\n}\n\ndef sort_contacts(contacts_file_path: str, output_file_path: str):\n    try:\n        contacts = pd.read_json(contacts_file_path)\n        contacts.sort_values([\"last_name\", \"first_name\"]).to_json(output_file_path, orient=\"records\")\n        return {\"message\": f\"Contacts sorted and saved to {output_file_path}\"}\n    except Exception as e:\n        return {\"error\": f\"Failed to sort contacts: {str(e)}\"}\n\ntools = [bakecake, a1_tool, a2_tool, a3_tool, a4_tool, a5_tool, a6_tool, a7_tool, a8_tool, a9_tool, a10_tool]\n\n\n\ndef query_gpt(user_input: str, tools: list[dict] = tools) -> dict[str, Any]:\n    response = requests.post(\n        url=\"https://aiproxy.sanand.workers.dev/openai/v1/chat/completions\",\n        headers={\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {AIPROXY_TOKEN}\"\n        },\n        json={\n            \"model\": \"gpt-4o-mini\",\n            \"messages\": [\n                {\n                    \"role\": \"system\",\n                    \"content\": \"\"\"\n                        Whenever you receive a system directory location, always make it into a realtive path, for example adding a . before it would make it relative path, rest is on you to manage, I just want the relative path\"\"\"\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": user_input\n                }\n            ],\n            \"tools\": tools,\n            \"tool_choice\": \"auto\"\n        }\n    )\n    return response.json()\n\n@app.get(\"/\")\ndef home():\n    return {\"Hello\": \"World\"}\n\n@app.get(\"/read\")\ndef read_file(path: str):\n    try:\n        with open(path, \"r\") as f:\n            return f.read()\n    except Exception as e:\n        raise HTTPException(status_code=404, detail=\"File does not exist\")\n\n@app.post(\"/run\")\nasync def run(task: str):\n    query = query_gpt(task)\n    print(query)  # Print the full response to inspect it.\n    \n    if 'choices' not in query:\n        raise HTTPException(status_code=500, detail=\"Invalid response format from GPT API\")\n    \n    try:\n        tool_calls = query['choices'][0]['message'].get('tool_calls', [])\n        if tool_calls:\n            func_name = tool_calls[0]['function']['name']\n            args = json.loads(tool_calls[0]['function']['arguments'])\n            \n            # Map function names to their respective functions\n            function_map = {\n                \"cakebake\": cakebake,\n                \"install_uv_and_run_datagen\": install_uv_and_run_datagen,\n                \"format_markdown_file\": format_markdown_file,\n                \"count_wednesdays\": count_wednesdays,\n                \"sort_contacts\": sort_contacts,\n                \"extract_recent_logs\": extract_recent_logs,\n                \"create_markdown_index\": create_markdown_index,\n                \"extract_sender_email\": extract_sender_email,\n                \"extract_credit_card_number\": extract_credit_card_number,\n                \"find_similar_comments\": find_similar_comments,\n                \"calculate_gold_ticket_sales\": calculate_gold_ticket_sales,\n            }\n            \n            if func_name in function_map:\n                output = function_map[func_name](**args)\n            else:\n                raise HTTPException(status_code=500, detail=\"Unknown function called\")\n        else:\n            raise HTTPException(status_code=500, detail=\"No function call found in response\")\n    except KeyError as e:\n        raise HTTPException(status_code=500, detail=f\"KeyError: Missing key in response - {str(e)}\")\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error processing the request: {str(e)}\")\n    \n    return output\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n\n\n\nand also i am sending postman request as \nhttp://localhost:8000/run?task=The\n file ./data/dates.txt contains a list of dates, one per line. Count the number of Wednesdays in the list, and write just the number to ./data/dates-wednesdays.txt\n\ndo I need to use dockerfile for this? i am still getting the same error as\n\n\nScreenshot 2025-02-14 231752\n1786×1065 74.8 KB\n\n\n@carlton\n , \n@Saransh_Saini\n , \n@Jivraj"
    },
    {
      "post_id": 595110,
      "author": "23f2004752",
      "created_at": "2025-02-14T17:55:28.433000",
      "content": "have you first post a request for task A1 as it creates the data folder along with  all the other files ."
    },
    {
      "post_id": 595117,
      "author": "Sakshi6479",
      "created_at": "2025-02-14T18:19:59.123000",
      "content": "no actually do we have to create another file for that or we have to request post in this one ? can you guide me for that step wise . it would be very helpful."
    },
    {
      "post_id": 595118,
      "author": "23f2004752",
      "created_at": "2025-02-14T18:22:49.379000",
      "content": "by running task A1 , it automatically creates a data folder along with all the files in it. Without running task A1 you can’t do rest of A tasks"
    },
    {
      "post_id": 595122,
      "author": "Sakshi6479",
      "created_at": "2025-02-14T18:38:09.127000",
      "content": "how can i run A1 task can elaborate a little bit. do i have to create data folder manually or  using this code by giving query taskA1 it will generate that folder ?"
    },
    {
      "post_id": 595123,
      "author": "23f2004752",
      "created_at": "2025-02-14T18:39:57.491000",
      "content": "simply give task=“task”\n\ntask: copy the task a_1 from project document"
    },
    {
      "post_id": 595125,
      "author": "Sakshi6479",
      "created_at": "2025-02-14T18:44:30.274000",
      "content": "it is showing\n\n\nINFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n{'id': 'chatcmpl-B0uvU556EOCy6HOPHV9ni7YJY403i', 'object': 'chat.completion', 'created': 1739558524, 'model': 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': None, 'tool_calls': [{'id': 'call_JXkfp14QEEo6M2zdgBXKduqi', 'type': 'function', 'function': {'name': 'install_uv_and_run_datagen', 'arguments': '{\"email\":\"24f2006749@ds.study.iitm.ac.in\"}'}}], 'refusal': None}, 'logprobs': None, 'finish_reason': 'tool_calls'}], 'usage': {'prompt_tokens': 732, 'completion_tokens': 30, 'total_tokens': 762, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'service_tier': 'default', 'system_fingerprint': 'fp_00428b782a', 'monthlyCost': 0.09109908, 'cost': 0.002376, 'monthlyRequests': 137}\nCollecting uv\n  Downloading uv-0.6.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nDownloading uv-0.6.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.3/16.3 MB 3.2 MB/s eta 0:00:00\nInstalling collected packages: uv\nSuccessfully installed uv-0.6.0\npython: can't open file '/home/sakshi-tds/tds_project1/https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/project-1/datagen.py': [Errno 2] No such file or directory\nINFO:     127.0.0.1:34758 - \"POST /run?task=Install%20uv%20(if%20required)%20and%20run%20https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/project-1/datagen.py%20with%2024f2006749@ds.study.iitm.ac.in%20as%20the%20only%20argument. HTTP/1.1\" 200 OK\n\n\n\nScreenshot 2025-02-15 001314\n1759×1645 228 KB"
    }
  ]
}